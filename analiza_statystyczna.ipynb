{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import f_oneway\n",
    "from scipy.stats import shapiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"statistics_data.xlsx\"  # zamień na właściwą ścieżkę do pliku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                BBC                         NaN  \\\n",
      "                 With preprocessing                         NaN   \n",
      "   Default BERT tokenizer (uncased)                         NaN   \n",
      "            Hyperparameters default Hyperparameters grid search   \n",
      "0                              0.93                        0.95   \n",
      "1                              0.97                        0.99   \n",
      "2                              0.96                        0.98   \n",
      "3                              0.93                        0.95   \n",
      "4                              0.96                        0.96   \n",
      "5                              0.97                        0.98   \n",
      "6                              0.98                        0.98   \n",
      "7                              0.98                        0.98   \n",
      "8                              0.96                        0.96   \n",
      "9                              0.97                        0.97   \n",
      "10                            0.961                        0.97   \n",
      "11         linear, c=1, gamma=scale      rbf, c=10, gamma=scale   \n",
      "12                              NaN                         NaN   \n",
      "13                              NaN                         NaN   \n",
      "\n",
      "                                                          \\\n",
      "                                                           \n",
      "        Cased BERT tokenizer                         NaN   \n",
      "     Hyperparameters default Hyperparameters grid search   \n",
      "0                       0.64                         0.7   \n",
      "1                       0.72                        0.69   \n",
      "2                       0.65                        0.65   \n",
      "3                       0.68                        0.68   \n",
      "4                       0.68                        0.72   \n",
      "5                       0.69                        0.69   \n",
      "6                       0.74                        0.74   \n",
      "7                       0.74                        0.78   \n",
      "8                       0.71                        0.67   \n",
      "9                       0.65                        0.74   \n",
      "10                      0.69                       0.706   \n",
      "11  linear, c=1, gamma=scale      rbf, c=10, gamma=scale   \n",
      "12                       NaN                         NaN   \n",
      "13                       NaN                         NaN   \n",
      "\n",
      "                                                          \\\n",
      "                                                           \n",
      "            Custom Tokenizer                         NaN   \n",
      "     Hyperparameters default Hyperparameters grid search   \n",
      "0                       0.95                        0.96   \n",
      "1                       0.99                        0.99   \n",
      "2                       0.99                        0.99   \n",
      "3                       0.99                        0.96   \n",
      "4                       0.94                        0.95   \n",
      "5                       0.96                        0.96   \n",
      "6                       0.97                        0.97   \n",
      "7                       0.99                        0.99   \n",
      "8                       0.97                        0.99   \n",
      "9                       0.97                        0.97   \n",
      "10                     0.972                       0.973   \n",
      "11  linear, c=1, gamma=scale       rbf, c=1, gamma=scale   \n",
      "12                       NaN                         NaN   \n",
      "13                       NaN                         NaN   \n",
      "\n",
      "                                                                 \\\n",
      "              Without preprocessing                         NaN   \n",
      "   Default BERT tokenizer (uncased)                         NaN   \n",
      "            Hyperparameters default Hyperparameters grid search   \n",
      "0                              0.95                        0.96   \n",
      "1                              0.96                        0.98   \n",
      "2                              0.95                        0.95   \n",
      "3                              0.97                        0.98   \n",
      "4                              0.99                        0.98   \n",
      "5                              0.95                        0.95   \n",
      "6                              0.99                        0.99   \n",
      "7                              0.99                        0.98   \n",
      "8                              0.97                        0.96   \n",
      "9                              0.97                        0.97   \n",
      "10                            0.969                        0.97   \n",
      "11         linear, c=1, gamma=scale      rbf, c=10, gamma=scale   \n",
      "12                              NaN                         NaN   \n",
      "13                              NaN                         NaN   \n",
      "\n",
      "                                                          ...  \\\n",
      "                                                          ...   \n",
      "        Cased BERT tokenizer                         NaN  ...   \n",
      "     Hyperparameters default Hyperparameters grid search  ...   \n",
      "0                       0.59                         0.6  ...   \n",
      "1                       0.63                        0.65  ...   \n",
      "2                       0.63                        0.65  ...   \n",
      "3                       0.62                        0.65  ...   \n",
      "4                        0.6                        0.62  ...   \n",
      "5                       0.62                        0.69  ...   \n",
      "6                       0.67                        0.66  ...   \n",
      "7                       0.71                        0.74  ...   \n",
      "8                       0.63                        0.62  ...   \n",
      "9                        0.6                        0.62  ...   \n",
      "10                      0.63                        0.65  ...   \n",
      "11  linear, c=1, gamma=scale      rbf, c=10, gamma=scale  ...   \n",
      "12                       NaN                         NaN  ...   \n",
      "13                       NaN                         NaN  ...   \n",
      "\n",
      "                                                          \\\n",
      "                                                           \n",
      "        Cased BERT tokenizer                         NaN   \n",
      "     Hyperparameters default Hyperparameters grid search   \n",
      "0                   0.049146                    0.050241   \n",
      "1                    0.06313                    0.056057   \n",
      "2                    0.06603                    0.064346   \n",
      "3                      0.101                       0.103   \n",
      "4                     0.0933                     0.09657   \n",
      "5                    0.08669                     0.08485   \n",
      "6                   0.051985                    0.054869   \n",
      "7                    0.07581                    0.090847   \n",
      "8                    0.06302                    0.061054   \n",
      "9                    0.05827                    0.065344   \n",
      "10                  0.070838                    0.072718   \n",
      "11  linear, c=1, gamma=scale                         NaN   \n",
      "12                       NaN                         NaN   \n",
      "13                       NaN                         NaN   \n",
      "\n",
      "                                                          \\\n",
      "                                                           \n",
      "            Custom Tokenizer                         NaN   \n",
      "     Hyperparameters default Hyperparameters grid search   \n",
      "0                       0.32                        0.29   \n",
      "1                        0.3                        0.31   \n",
      "2                       0.35                        0.32   \n",
      "3                       0.33                        0.33   \n",
      "4                       0.25                        0.29   \n",
      "5                       0.25                        0.29   \n",
      "6                       0.25                        0.35   \n",
      "7                       0.25                        0.25   \n",
      "8                       0.28                        0.29   \n",
      "9                       0.27                        0.27   \n",
      "10                     0.285                       0.299   \n",
      "11  linear, c=1, gamma=scale       rbf, c=1, gamma=scale   \n",
      "12                       NaN                tutaj collab   \n",
      "13                       NaN                    tutaj vs   \n",
      "\n",
      "                                                                 \\\n",
      "              Without preprocessing                         NaN   \n",
      "   Default BERT tokenizer (uncased)                         NaN   \n",
      "            Hyperparameters default Hyperparameters grid search   \n",
      "0                              0.25                        0.25   \n",
      "1                              0.27                        0.27   \n",
      "2                              0.33                        0.31   \n",
      "3                              0.36                        0.36   \n",
      "4                              0.31                        0.31   \n",
      "5                              0.28                        0.28   \n",
      "6                              0.31                        0.32   \n",
      "7                              0.28                        0.29   \n",
      "8                              0.28                        0.29   \n",
      "9                              0.28                        0.29   \n",
      "10                            0.295                       0.297   \n",
      "11         linear, c=1, gamma=scale  linear, c=0,1, gamma=scale   \n",
      "12                              NaN                         NaN   \n",
      "13                              NaN                         NaN   \n",
      "\n",
      "                                                          \\\n",
      "                                                           \n",
      "        Cased BERT tokenizer                         NaN   \n",
      "     Hyperparameters default Hyperparameters grid search   \n",
      "0                      0.068                     0.06757   \n",
      "1                     0.0346                    0.039165   \n",
      "2                     0.0726                    0.076156   \n",
      "3                     0.1294                     0.12909   \n",
      "4                     0.0667                    0.066898   \n",
      "5                    0.05617                     0.05617   \n",
      "6                    0.09809                    0.101014   \n",
      "7                    0.14232                     0.13677   \n",
      "8                   0.054536                    0.054536   \n",
      "9                    0.08669                     0.08669   \n",
      "10                  0.080911                    0.081406   \n",
      "11  linear, c=1, gamma=scale                         NaN   \n",
      "12                       NaN                         NaN   \n",
      "13                       NaN                         NaN   \n",
      "\n",
      "                                                          \n",
      "                                                          \n",
      "            Custom Tokenizer                         NaN  \n",
      "     Hyperparameters default Hyperparameters grid search  \n",
      "0                    0.19754                      0.1975  \n",
      "1                    0.10845                     0.10845  \n",
      "2                    0.24463                     0.24463  \n",
      "3                    0.15807                     0.15807  \n",
      "4                   0.151636                    0.151636  \n",
      "5                    0.35067                    0.350677  \n",
      "6                    0.23298                    0.232983  \n",
      "7                    0.11039                     0.11039  \n",
      "8                   0.157309                    0.157309  \n",
      "9                    0.20456                    0.204762  \n",
      "10                  0.191624                    0.191641  \n",
      "11  linear, c=1, gamma=scale                         NaN  \n",
      "12                       NaN                         NaN  \n",
      "13                       NaN                         NaN  \n",
      "\n",
      "[14 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(file_path, header = None)\n",
    "df = df.dropna(axis=0, how='all')\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "# Przypisanie wierszy do kategorii\n",
    "categories = df.iloc[:4].values.tolist()\n",
    "\n",
    "# Przypisanie kategorii do nagłówków kolumn\n",
    "df.columns = categories\n",
    "\n",
    "# Usunięcie pierwszych czterech wierszy, które były wykorzystywane jako nagłówki kolumn\n",
    "df = df.iloc[4:]\n",
    "\n",
    "# Reset indeksów\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "# Wyświetlenie wyników\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizator: Default BERT tokenizer (uncased) - Z preprocessingu\n",
      "Wartość statystyki testu Shapiro-Wilka: 0.8296725749969482\n",
      "Wartość p dla testu Shapiro-Wilka: 0.023115525022149086\n",
      "\n",
      "Tokenizator: Default BERT tokenizer (uncased) - Bez preprocessingu\n",
      "Wartość statystyki testu Shapiro-Wilka: 0.8573563098907471\n",
      "Wartość p dla testu Shapiro-Wilka: 0.05320848152041435\n",
      "\n",
      "Tokenizator: Cased BERT tokenizer - Z preprocessingu\n",
      "Wartość statystyki testu Shapiro-Wilka: 0.9323931336402893\n",
      "Wartość p dla testu Shapiro-Wilka: 0.4355674386024475\n",
      "\n",
      "Tokenizator: Cased BERT tokenizer - Bez preprocessingu\n",
      "Wartość statystyki testu Shapiro-Wilka: 0.8503646850585938\n",
      "Wartość p dla testu Shapiro-Wilka: 0.043147556483745575\n",
      "\n",
      "Tokenizator: Custom tokenizer - Z preprocessingu\n",
      "Wartość statystyki testu Shapiro-Wilka: 0.8803328275680542\n",
      "Wartość p dla testu Shapiro-Wilka: 0.1050635501742363\n",
      "\n",
      "Tokenizator: Custom tokenizer - Bez preprocessingu\n",
      "Wartość statystyki testu Shapiro-Wilka: 0.9292619228363037\n",
      "Wartość p dla testu Shapiro-Wilka: 0.40343499183654785\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenizator: Default BERT tokenizer (uncased)\n",
    "results_default_with_preprocessing = df['BBC']['With preprocessing']['Default BERT tokenizer (uncased)']['Hyperparameters default']\n",
    "results_default_without_preprocessing = df['BBC']['Without preprocessing']['Default BERT tokenizer (uncased)']['Hyperparameters default']\n",
    "\n",
    "# Test Shapiro-Wilka dla danych z i bez preprocessingu dla tokenizatora domyślnego\n",
    "statistic, p_value_shapiro = shapiro(results_default_with_preprocessing)\n",
    "print(\"Tokenizator: Default BERT tokenizer (uncased) - Z preprocessingu\")\n",
    "print(\"Wartość statystyki testu Shapiro-Wilka:\", statistic)\n",
    "print(\"Wartość p dla testu Shapiro-Wilka:\", p_value_shapiro)\n",
    "print()\n",
    "\n",
    "statistic, p_value_shapiro = shapiro(results_default_without_preprocessing)\n",
    "print(\"Tokenizator: Default BERT tokenizer (uncased) - Bez preprocessingu\")\n",
    "print(\"Wartość statystyki testu Shapiro-Wilka:\", statistic)\n",
    "print(\"Wartość p dla testu Shapiro-Wilka:\", p_value_shapiro)\n",
    "print()\n",
    "\n",
    "# Tokenizator: Cased BERT tokenizer\n",
    "results_cased_with_preprocessing = df['BBC']['With preprocessing']['Cased BERT tokenizer']['Hyperparameters default']\n",
    "results_cased_without_preprocessing = df['BBC']['Without preprocessing']['Cased BERT tokenizer']['Hyperparameters default']\n",
    "\n",
    "# Test Shapiro-Wilka dla danych z i bez preprocessingu dla cased BERT tokenizer\n",
    "statistic, p_value_shapiro = shapiro(results_cased_with_preprocessing)\n",
    "print(\"Tokenizator: Cased BERT tokenizer - Z preprocessingu\")\n",
    "print(\"Wartość statystyki testu Shapiro-Wilka:\", statistic)\n",
    "print(\"Wartość p dla testu Shapiro-Wilka:\", p_value_shapiro)\n",
    "print()\n",
    "\n",
    "statistic, p_value_shapiro = shapiro(results_cased_without_preprocessing)\n",
    "print(\"Tokenizator: Cased BERT tokenizer - Bez preprocessingu\")\n",
    "print(\"Wartość statystyki testu Shapiro-Wilka:\", statistic)\n",
    "print(\"Wartość p dla testu Shapiro-Wilka:\", p_value_shapiro)\n",
    "print()\n",
    "\n",
    "# Tokenizator: Custom tokenizer\n",
    "results_custom_with_preprocessing = df['BBC']['With preprocessing']['Custom Tokenizer']['Hyperparameters default']\n",
    "results_custom_without_preprocessing = df['BBC']['Without preprocessing']['Custom Tokenizer']['Hyperparameters default']\n",
    "\n",
    "# Test Shapiro-Wilka dla danych z i bez preprocessingu dla custom tokenizer\n",
    "statistic, p_value_shapiro = shapiro(results_custom_with_preprocessing)\n",
    "print(\"Tokenizator: Custom tokenizer - Z preprocessingu\")\n",
    "print(\"Wartość statystyki testu Shapiro-Wilka:\", statistic)\n",
    "print(\"Wartość p dla testu Shapiro-Wilka:\", p_value_shapiro)\n",
    "print()\n",
    "\n",
    "statistic, p_value_shapiro = shapiro(results_custom_without_preprocessing)\n",
    "print(\"Tokenizator: Custom tokenizer - Bez preprocessingu\")\n",
    "print(\"Wartość statystyki testu Shapiro-Wilka:\", statistic)\n",
    "print(\"Wartość p dla testu Shapiro-Wilka:\", p_value_shapiro)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizator: Default BERT tokenizer (uncased) - Z preprocessingu\n",
      "Wartość statystyki testu Shapiro-Wilka: 0.9080870747566223\n",
      "Wartość p dla testu Shapiro-Wilka: 0.23145587742328644\n",
      "\n",
      "Tokenizator: Default BERT tokenizer (uncased) - Bez preprocessingu\n",
      "Wartość statystyki testu Shapiro-Wilka: 0.9080870747566223\n",
      "Wartość p dla testu Shapiro-Wilka: 0.23145587742328644\n",
      "\n",
      "Tokenizator: Cased BERT tokenizer - Z preprocessingu\n",
      "Wartość statystyki testu Shapiro-Wilka: 0.9693017601966858\n",
      "Wartość p dla testu Shapiro-Wilka: 0.879393994808197\n",
      "\n",
      "Tokenizator: Cased BERT tokenizer - Bez preprocessingu\n",
      "Wartość statystyki testu Shapiro-Wilka: 0.8808636665344238\n",
      "Wartość p dla testu Shapiro-Wilka: 0.10670565813779831\n",
      "\n",
      "Tokenizator: Custom tokenizer - Z preprocessingu\n",
      "Wartość statystyki testu Shapiro-Wilka: 0.861517608165741\n",
      "Wartość p dla testu Shapiro-Wilka: 0.06025022640824318\n",
      "\n",
      "Tokenizator: Custom tokenizer - Bez preprocessingu\n",
      "Wartość statystyki testu Shapiro-Wilka: 0.9134095907211304\n",
      "Wartość p dla testu Shapiro-Wilka: 0.2675044536590576\n"
     ]
    }
   ],
   "source": [
    "# Tokenizator: Default BERT tokenizer (uncased)\n",
    "results_default_with_preprocessing = df['BBC']['With preprocessing']['Default BERT tokenizer (uncased)']['Hyperparameters grid search']\n",
    "results_default_without_preprocessing = df['BBC']['Without preprocessing']['Default BERT tokenizer (uncased)']['Hyperparameters grid search']\n",
    "\n",
    "# Test Shapiro-Wilka dla danych z i bez preprocessingu dla tokenizatora domyślnego\n",
    "statistic, p_value_shapiro = shapiro(results_default_with_preprocessing)\n",
    "print(\"Tokenizator: Default BERT tokenizer (uncased) - Z preprocessingu\")\n",
    "print(\"Wartość statystyki testu Shapiro-Wilka:\", statistic)\n",
    "print(\"Wartość p dla testu Shapiro-Wilka:\", p_value_shapiro)\n",
    "print()\n",
    "\n",
    "statistic, p_value_shapiro = shapiro(results_default_without_preprocessing)\n",
    "print(\"Tokenizator: Default BERT tokenizer (uncased) - Bez preprocessingu\")\n",
    "print(\"Wartość statystyki testu Shapiro-Wilka:\", statistic)\n",
    "print(\"Wartość p dla testu Shapiro-Wilka:\", p_value_shapiro)\n",
    "print()\n",
    "\n",
    "# Tokenizator: Cased BERT tokenizer\n",
    "results_cased_with_preprocessing = df['BBC']['With preprocessing']['Cased BERT tokenizer']['Hyperparameters grid search']\n",
    "results_cased_without_preprocessing = df['BBC']['Without preprocessing']['Cased BERT tokenizer']['Hyperparameters grid search']\n",
    "\n",
    "# Test Shapiro-Wilka dla danych z i bez preprocessingu dla cased BERT tokenizer\n",
    "statistic, p_value_shapiro = shapiro(results_cased_with_preprocessing)\n",
    "print(\"Tokenizator: Cased BERT tokenizer - Z preprocessingu\")\n",
    "print(\"Wartość statystyki testu Shapiro-Wilka:\", statistic)\n",
    "print(\"Wartość p dla testu Shapiro-Wilka:\", p_value_shapiro)\n",
    "print()\n",
    "\n",
    "statistic, p_value_shapiro = shapiro(results_cased_without_preprocessing)\n",
    "print(\"Tokenizator: Cased BERT tokenizer - Bez preprocessingu\")\n",
    "print(\"Wartość statystyki testu Shapiro-Wilka:\", statistic)\n",
    "print(\"Wartość p dla testu Shapiro-Wilka:\", p_value_shapiro)\n",
    "print()\n",
    "\n",
    "# Tokenizator: Custom tokenizer\n",
    "results_custom_with_preprocessing = df['BBC']['With preprocessing']['Custom Tokenizer']['Hyperparameters grid search']\n",
    "results_custom_without_preprocessing = df['BBC']['Without preprocessing']['Custom Tokenizer']['Hyperparameters grid search']\n",
    "\n",
    "# Test Shapiro-Wilka dla danych z i bez preprocessingu dla custom tokenizer\n",
    "statistic, p_value_shapiro = shapiro(results_custom_with_preprocessing)\n",
    "print(\"Tokenizator: Custom tokenizer - Z preprocessingu\")\n",
    "print(\"Wartość statystyki testu Shapiro-Wilka:\", statistic)\n",
    "print(\"Wartość p dla testu Shapiro-Wilka:\", p_value_shapiro)\n",
    "print()\n",
    "\n",
    "statistic, p_value_shapiro = shapiro(results_custom_without_preprocessing)\n",
    "print(\"Tokenizator: Custom tokenizer - Bez preprocessingu\")\n",
    "print(\"Wartość statystyki testu Shapiro-Wilka:\", statistic)\n",
    "print(\"Wartość p dla testu Shapiro-Wilka:\", p_value_shapiro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizator: Default BERT tokenizer (uncased) - Z preprocessingu (IMDb)\n",
      "Wartość statystyki testu Shapiro-Wilka: 0.8952979445457458\n",
      "Wartość p dla testu Shapiro-Wilka: 0.16182848811149597\n",
      "\n",
      "Tokenizator: Default BERT tokenizer (uncased) - Bez preprocessingu (IMDb)\n",
      "Wartość statystyki testu Shapiro-Wilka: 0.949944794178009\n",
      "Wartość p dla testu Shapiro-Wilka: 0.643248438835144\n",
      "\n",
      "Tokenizator: Cased BERT tokenizer - Z preprocessingu (IMDb)\n",
      "Wartość statystyki testu Shapiro-Wilka: 0.9176630973815918\n",
      "Wartość p dla testu Shapiro-Wilka: 0.29965442419052124\n",
      "\n",
      "Tokenizator: Cased BERT tokenizer - Bez preprocessingu (IMDb)\n",
      "Wartość statystyki testu Shapiro-Wilka: 0.9338507056236267\n",
      "Wartość p dla testu Shapiro-Wilka: 0.4511069059371948\n",
      "\n",
      "Tokenizator: Custom tokenizer - Z preprocessingu (IMDb)\n",
      "Wartość statystyki testu Shapiro-Wilka: 0.965495765209198\n",
      "Wartość p dla testu Shapiro-Wilka: 0.8377962112426758\n",
      "\n",
      "Tokenizator: Custom tokenizer - Bez preprocessingu (IMDb)\n",
      "Wartość statystyki testu Shapiro-Wilka: 0.9126698970794678\n",
      "Wartość p dla testu Shapiro-Wilka: 0.2622223496437073\n"
     ]
    }
   ],
   "source": [
    "# Tokenizator: Default BERT tokenizer (uncased)\n",
    "results_default_with_preprocessing_imdb = df['IMDb']['With preprocessing']['Default BERT tokenizer (uncased)']['Hyperparameters grid search']\n",
    "results_default_without_preprocessing_imdb = df['IMDb']['Without preprocessing']['Default BERT tokenizer (uncased)']['Hyperparameters grid search']\n",
    "\n",
    "# Test Shapiro-Wilka dla danych z i bez preprocessingu dla tokenizatora domyślnego\n",
    "statistic, p_value_shapiro = shapiro(results_default_with_preprocessing_imdb)\n",
    "print(\"Tokenizator: Default BERT tokenizer (uncased) - Z preprocessingu (IMDb)\")\n",
    "print(\"Wartość statystyki testu Shapiro-Wilka:\", statistic)\n",
    "print(\"Wartość p dla testu Shapiro-Wilka:\", p_value_shapiro)\n",
    "print()\n",
    "\n",
    "statistic, p_value_shapiro = shapiro(results_default_without_preprocessing_imdb)\n",
    "print(\"Tokenizator: Default BERT tokenizer (uncased) - Bez preprocessingu (IMDb)\")\n",
    "print(\"Wartość statystyki testu Shapiro-Wilka:\", statistic)\n",
    "print(\"Wartość p dla testu Shapiro-Wilka:\", p_value_shapiro)\n",
    "print()\n",
    "\n",
    "# Tokenizator: Cased BERT tokenizer\n",
    "results_cased_with_preprocessing_imdb = df['IMDb']['With preprocessing']['Cased BERT tokenizer']['Hyperparameters grid search']\n",
    "results_cased_without_preprocessing_imdb = df['IMDb']['Without preprocessing']['Cased BERT tokenizer']['Hyperparameters grid search']\n",
    "\n",
    "# Test Shapiro-Wilka dla danych z i bez preprocessingu dla cased BERT tokenizer\n",
    "statistic, p_value_shapiro = shapiro(results_cased_with_preprocessing_imdb)\n",
    "print(\"Tokenizator: Cased BERT tokenizer - Z preprocessingu (IMDb)\")\n",
    "print(\"Wartość statystyki testu Shapiro-Wilka:\", statistic)\n",
    "print(\"Wartość p dla testu Shapiro-Wilka:\", p_value_shapiro)\n",
    "print()\n",
    "\n",
    "statistic, p_value_shapiro = shapiro(results_cased_without_preprocessing_imdb)\n",
    "print(\"Tokenizator: Cased BERT tokenizer - Bez preprocessingu (IMDb)\")\n",
    "print(\"Wartość statystyki testu Shapiro-Wilka:\", statistic)\n",
    "print(\"Wartość p dla testu Shapiro-Wilka:\", p_value_shapiro)\n",
    "print()\n",
    "\n",
    "# Tokenizator: Custom tokenizer\n",
    "results_custom_with_preprocessing_imdb = df['IMDb']['With preprocessing']['Custom Tokenizer']['Hyperparameters grid search']\n",
    "results_custom_without_preprocessing_imdb = df['IMDb']['Without preprocessing']['Custom Tokenizer']['Hyperparameters grid search']\n",
    "\n",
    "# Test Shapiro-Wilka dla danych z i bez preprocessingu dla custom tokenizer\n",
    "statistic, p_value_shapiro = shapiro(results_custom_with_preprocessing_imdb)\n",
    "print(\"Tokenizator: Custom tokenizer - Z preprocessingu (IMDb)\")\n",
    "print(\"Wartość statystyki testu Shapiro-Wilka:\", statistic)\n",
    "print(\"Wartość p dla testu Shapiro-Wilka:\", p_value_shapiro)\n",
    "print()\n",
    "\n",
    "statistic, p_value_shapiro = shapiro(results_custom_without_preprocessing_imdb)\n",
    "print(\"Tokenizator: Custom tokenizer - Bez preprocessingu (IMDb)\")\n",
    "print(\"Wartość statystyki testu Shapiro-Wilka:\", statistic)\n",
    "print(\"Wartość p dla testu Shapiro-Wilka:\", p_value_shapiro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizator: Default BERT tokenizer (uncased) - Z preprocessingu (IMDb)\n",
      "Wartość statystyki testu Shapiro-Wilka: 0.9590778350830078\n",
      "Wartość p dla testu Shapiro-Wilka: 0.7601335048675537\n",
      "\n",
      "Tokenizator: Default BERT tokenizer (uncased) - Bez preprocessingu (IMDb)\n",
      "Wartość statystyki testu Shapiro-Wilka: 0.9274464249610901\n",
      "Wartość p dla testu Shapiro-Wilka: 0.38560202717781067\n",
      "\n",
      "Tokenizator: Cased BERT tokenizer - Z preprocessingu (IMDb)\n",
      "Wartość statystyki testu Shapiro-Wilka: 0.9422882199287415\n",
      "Wartość p dla testu Shapiro-Wilka: 0.5477616190910339\n",
      "\n",
      "Tokenizator: Cased BERT tokenizer - Bez preprocessingu (IMDb)\n",
      "Wartość statystyki testu Shapiro-Wilka: 0.9360029697418213\n",
      "Wartość p dla testu Shapiro-Wilka: 0.4747076630592346\n",
      "\n",
      "Tokenizator: Custom tokenizer - Z preprocessingu (IMDb)\n",
      "Wartość statystyki testu Shapiro-Wilka: 0.8835641145706177\n",
      "Wartość p dla testu Shapiro-Wilka: 0.1154436469078064\n",
      "\n",
      "Tokenizator: Custom tokenizer - Bez preprocessingu (IMDb)\n",
      "Wartość statystyki testu Shapiro-Wilka: 0.912540078163147\n",
      "Wartość p dla testu Shapiro-Wilka: 0.2613046169281006\n"
     ]
    }
   ],
   "source": [
    "# Tokenizator: Default BERT tokenizer (uncased)\n",
    "results_default_with_preprocessing_imdb = df['IMDb']['With preprocessing']['Default BERT tokenizer (uncased)']['Hyperparameters default']\n",
    "results_default_without_preprocessing_imdb = df['IMDb']['Without preprocessing']['Default BERT tokenizer (uncased)']['Hyperparameters default']\n",
    "\n",
    "# Test Shapiro-Wilka dla danych z i bez preprocessingu dla tokenizatora domyślnego\n",
    "statistic, p_value_shapiro = shapiro(results_default_with_preprocessing_imdb)\n",
    "print(\"Tokenizator: Default BERT tokenizer (uncased) - Z preprocessingu (IMDb)\")\n",
    "print(\"Wartość statystyki testu Shapiro-Wilka:\", statistic)\n",
    "print(\"Wartość p dla testu Shapiro-Wilka:\", p_value_shapiro)\n",
    "print()\n",
    "\n",
    "statistic, p_value_shapiro = shapiro(results_default_without_preprocessing_imdb)\n",
    "print(\"Tokenizator: Default BERT tokenizer (uncased) - Bez preprocessingu (IMDb)\")\n",
    "print(\"Wartość statystyki testu Shapiro-Wilka:\", statistic)\n",
    "print(\"Wartość p dla testu Shapiro-Wilka:\", p_value_shapiro)\n",
    "print()\n",
    "\n",
    "# Tokenizator: Cased BERT tokenizer\n",
    "results_cased_with_preprocessing_imdb = df['IMDb']['With preprocessing']['Cased BERT tokenizer']['Hyperparameters default']\n",
    "results_cased_without_preprocessing_imdb = df['IMDb']['Without preprocessing']['Cased BERT tokenizer']['Hyperparameters default']\n",
    "\n",
    "# Test Shapiro-Wilka dla danych z i bez preprocessingu dla cased BERT tokenizer\n",
    "statistic, p_value_shapiro = shapiro(results_cased_with_preprocessing_imdb)\n",
    "print(\"Tokenizator: Cased BERT tokenizer - Z preprocessingu (IMDb)\")\n",
    "print(\"Wartość statystyki testu Shapiro-Wilka:\", statistic)\n",
    "print(\"Wartość p dla testu Shapiro-Wilka:\", p_value_shapiro)\n",
    "print()\n",
    "\n",
    "statistic, p_value_shapiro = shapiro(results_cased_without_preprocessing_imdb)\n",
    "print(\"Tokenizator: Cased BERT tokenizer - Bez preprocessingu (IMDb)\")\n",
    "print(\"Wartość statystyki testu Shapiro-Wilka:\", statistic)\n",
    "print(\"Wartość p dla testu Shapiro-Wilka:\", p_value_shapiro)\n",
    "print()\n",
    "\n",
    "# Tokenizator: Custom tokenizer\n",
    "results_custom_with_preprocessing_imdb = df['IMDb']['With preprocessing']['Custom Tokenizer']['Hyperparameters default']\n",
    "results_custom_without_preprocessing_imdb = df['IMDb']['Without preprocessing']['Custom Tokenizer']['Hyperparameters default']\n",
    "\n",
    "# Test Shapiro-Wilka dla danych z i bez preprocessingu dla custom tokenizer\n",
    "statistic, p_value_shapiro = shapiro(results_custom_with_preprocessing_imdb)\n",
    "print(\"Tokenizator: Custom tokenizer - Z preprocessingu (IMDb)\")\n",
    "print(\"Wartość statystyki testu Shapiro-Wilka:\", statistic)\n",
    "print(\"Wartość p dla testu Shapiro-Wilka:\", p_value_shapiro)\n",
    "print()\n",
    "\n",
    "statistic, p_value_shapiro = shapiro(results_custom_without_preprocessing_imdb)\n",
    "print(\"Tokenizator: Custom tokenizer - Bez preprocessingu (IMDb)\")\n",
    "print(\"Wartość statystyki testu Shapiro-Wilka:\", statistic)\n",
    "print(\"Wartość p dla testu Shapiro-Wilka:\", p_value_shapiro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBC Preprocessing Comparisons\n",
      "  Dataset                         Tokenizer              Hyperparameters  \\\n",
      "0     BBC              Cased BERT Tokenizer      Hyperparameters default   \n",
      "1     BBC              Cased BERT Tokenizer  Hyperparameters grid search   \n",
      "2     BBC                  Custom Tokenizer      Hyperparameters default   \n",
      "3     BBC                  Custom Tokenizer  Hyperparameters grid search   \n",
      "4     BBC  Default BERT Tokenizer (uncased)      Hyperparameters default   \n",
      "5     BBC  Default BERT Tokenizer (uncased)  Hyperparameters grid search   \n",
      "\n",
      "   t-test p-value  Wilcoxon p-value  \n",
      "0        0.000003          0.000977  \n",
      "1        0.000926          0.007632  \n",
      "2        0.425506          0.717562  \n",
      "3        0.468806          0.573992  \n",
      "4        0.166404          0.234946  \n",
      "5        1.000000          1.000000  \n",
      "\n",
      "IMDb Preprocessing Comparisons\n",
      "  Dataset                         Tokenizer              Hyperparameters  \\\n",
      "0    IMDb              Cased BERT Tokenizer      Hyperparameters default   \n",
      "1    IMDb              Cased BERT Tokenizer  Hyperparameters grid search   \n",
      "2    IMDb                  Custom Tokenizer      Hyperparameters default   \n",
      "3    IMDb                  Custom Tokenizer  Hyperparameters grid search   \n",
      "4    IMDb  Default BERT Tokenizer (uncased)      Hyperparameters default   \n",
      "5    IMDb  Default BERT Tokenizer (uncased)  Hyperparameters grid search   \n",
      "\n",
      "   t-test p-value  Wilcoxon p-value  \n",
      "0        0.317291          0.464844  \n",
      "1        0.304591          0.365234  \n",
      "2        0.003116          0.009766  \n",
      "3        0.000406          0.001953  \n",
      "4        0.551732          0.878088  \n",
      "5        0.645815          0.759311  \n",
      "\n",
      "BBC Hyperparameters Comparisons\n",
      "  Dataset                         Tokenizer          Preprocessing  \\\n",
      "0     BBC              Cased BERT Tokenizer     With preprocessing   \n",
      "1     BBC              Cased BERT Tokenizer  Without preprocessing   \n",
      "2     BBC                  Custom Tokenizer     With preprocessing   \n",
      "3     BBC                  Custom Tokenizer  Without preprocessing   \n",
      "4     BBC  Default BERT Tokenizer (uncased)     With preprocessing   \n",
      "5     BBC  Default BERT Tokenizer (uncased)  Without preprocessing   \n",
      "\n",
      "   t-test p-value  Wilcoxon p-value  \n",
      "0        0.198396          0.150056  \n",
      "1        0.011390          0.006836  \n",
      "2        0.791373          0.498225  \n",
      "3        0.498806          0.570643  \n",
      "4        0.010089          0.026857  \n",
      "5        0.732462          0.725721  \n",
      "\n",
      "IMDb Hyperparameters Comparisons\n",
      "  Dataset                         Tokenizer          Preprocessing  \\\n",
      "0    IMDb              Cased BERT Tokenizer     With preprocessing   \n",
      "1    IMDb              Cased BERT Tokenizer  Without preprocessing   \n",
      "2    IMDb                  Custom Tokenizer     With preprocessing   \n",
      "3    IMDb                  Custom Tokenizer  Without preprocessing   \n",
      "4    IMDb  Default BERT Tokenizer (uncased)     With preprocessing   \n",
      "5    IMDb  Default BERT Tokenizer (uncased)  Without preprocessing   \n",
      "\n",
      "   t-test p-value  Wilcoxon p-value  \n",
      "0        0.299867          0.240234  \n",
      "1        0.550520          0.483840  \n",
      "2        0.230766          0.207021  \n",
      "3        0.385478          0.345231  \n",
      "4        0.136658          0.205903  \n",
      "5        0.464289          0.340085  \n",
      "\n",
      "BBC Tokenizers Comparisons\n",
      "  Dataset          Preprocessing              Hyperparameters  \\\n",
      "0     BBC     With preprocessing      Hyperparameters default   \n",
      "1     BBC     With preprocessing  Hyperparameters grid search   \n",
      "2     BBC  Without preprocessing      Hyperparameters default   \n",
      "3     BBC  Without preprocessing  Hyperparameters grid search   \n",
      "\n",
      "   T-test p-value (Default vs Cased)  T-test p-value (Default vs Custom)  \\\n",
      "0                       1.841690e-11                            0.129995   \n",
      "1                       4.046346e-10                            0.476565   \n",
      "2                       3.261027e-12                            0.464289   \n",
      "3                       1.035553e-10                            0.582043   \n",
      "\n",
      "   T-test p-value (Cased vs Custom)  Wilcoxon p-value (Default vs Cased)  \\\n",
      "0                      8.567470e-11                             0.000977   \n",
      "1                      1.010739e-09                             0.000977   \n",
      "2                      1.029178e-11                             0.000977   \n",
      "3                      4.638894e-11                             0.000977   \n",
      "\n",
      "   Wilcoxon p-value (Default vs Custom)  Wilcoxon p-value (Cased vs Custom)  \n",
      "0                              0.123565                            0.000977  \n",
      "1                              0.501227                            0.000977  \n",
      "2                              0.527089                            0.000977  \n",
      "3                              0.725721                            0.000977  \n",
      "\n",
      "IMDb Tokenizers Comparisons\n",
      "  Dataset          Preprocessing              Hyperparameters  \\\n",
      "0    IMDb     With preprocessing      Hyperparameters default   \n",
      "1    IMDb     With preprocessing  Hyperparameters grid search   \n",
      "2    IMDb  Without preprocessing      Hyperparameters default   \n",
      "3    IMDb  Without preprocessing  Hyperparameters grid search   \n",
      "\n",
      "   T-test p-value (Default vs Cased)  T-test p-value (Default vs Custom)  \\\n",
      "0                       2.109117e-09                            0.912646   \n",
      "1                       1.946608e-09                            0.484146   \n",
      "2                       1.094521e-09                            0.000981   \n",
      "3                       1.252791e-10                            0.000978   \n",
      "\n",
      "   T-test p-value (Cased vs Custom)  Wilcoxon p-value (Default vs Cased)  \\\n",
      "0                      8.140675e-09                             0.000977   \n",
      "1                      1.483332e-09                             0.000977   \n",
      "2                      1.210512e-03                             0.000977   \n",
      "3                      1.137638e-03                             0.000977   \n",
      "\n",
      "   Wilcoxon p-value (Default vs Custom)  Wilcoxon p-value (Cased vs Custom)  \n",
      "0                              0.858955                            0.000977  \n",
      "1                              0.483840                            0.000977  \n",
      "2                              0.002930                            0.002930  \n",
      "3                              0.004883                            0.001953  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micho\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: Exact p-value calculation does not work if there are zeros. Switching to normal approximation.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "C:\\Users\\micho\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: Sample size too small for normal approximation.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import f_oneway, shapiro, ttest_rel, wilcoxon\n",
    "\n",
    "# Load the data\n",
    "file_path = \"plik_analiza_statystyczna.xlsx\"  # Change to the correct file path\n",
    "\n",
    "df = pd.read_excel(file_path, header=None)\n",
    "df = df.dropna(axis=0, how='all')\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "categories = df.iloc[:4].values.tolist()\n",
    "df.columns = pd.MultiIndex.from_tuples(list(zip(*categories)))\n",
    "df = df.iloc[4:]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "def compare_preprocessing(df, dataset_name):\n",
    "    results = []\n",
    "    tokenizers = df.columns.levels[2]\n",
    "    for tokenizer in tokenizers:\n",
    "        for config in ['Hyperparameters default', 'Hyperparameters grid search']:\n",
    "            with_preprocessing = df[dataset_name]['With preprocessing'][tokenizer][config]\n",
    "            without_preprocessing = df[dataset_name]['Without preprocessing'][tokenizer][config]\n",
    "            t_stat, t_p = ttest_rel(with_preprocessing, without_preprocessing)\n",
    "            w_stat, w_p = wilcoxon(with_preprocessing, without_preprocessing)\n",
    "            results.append({\n",
    "                'Dataset': dataset_name,\n",
    "                'Tokenizer': tokenizer,\n",
    "                'Hyperparameters': config,\n",
    "                't-test p-value': t_p,\n",
    "                'Wilcoxon p-value': w_p\n",
    "            })\n",
    "    return results\n",
    "\n",
    "def compare_hyperparameters(df, dataset_name):\n",
    "    results = []\n",
    "    tokenizers = df.columns.levels[2]\n",
    "    preprocessing_options = df.columns.levels[1]\n",
    "    for tokenizer in tokenizers:\n",
    "        for preprocessing in preprocessing_options:\n",
    "            data_default = df[dataset_name][preprocessing][tokenizer]['Hyperparameters default']\n",
    "            data_grid = df[dataset_name][preprocessing][tokenizer]['Hyperparameters grid search']\n",
    "            t_stat, t_p = ttest_rel(data_default, data_grid)\n",
    "            w_stat, w_p = wilcoxon(data_default, data_grid)\n",
    "            results.append({\n",
    "                'Dataset': dataset_name,\n",
    "                'Tokenizer': tokenizer,\n",
    "                'Preprocessing': preprocessing,\n",
    "                't-test p-value': t_p,\n",
    "                'Wilcoxon p-value': w_p\n",
    "            })\n",
    "    return results\n",
    "\n",
    "def compare_tokenizers(df, dataset_name):\n",
    "    results = []\n",
    "    preprocessing_options = df.columns.levels[1]\n",
    "    hyperparameters_options = df.columns.levels[3]\n",
    "    for preprocessing in preprocessing_options:\n",
    "        for hyperparameters in hyperparameters_options:\n",
    "            data_default_bert = df[dataset_name][preprocessing]['Default BERT Tokenizer (uncased)'][hyperparameters]\n",
    "            data_cased_bert = df[dataset_name][preprocessing]['Cased BERT Tokenizer'][hyperparameters]\n",
    "            data_custom_tokenizer = df[dataset_name][preprocessing]['Custom Tokenizer'][hyperparameters]\n",
    "            \n",
    "            # T-test for each pair of tokenizers\n",
    "            t_stat_default_vs_cased, t_p_default_vs_cased = ttest_rel(data_default_bert, data_cased_bert)\n",
    "            t_stat_default_vs_custom, t_p_default_vs_custom = ttest_rel(data_default_bert, data_custom_tokenizer)\n",
    "            t_stat_cased_vs_custom, t_p_cased_vs_custom = ttest_rel(data_cased_bert, data_custom_tokenizer)\n",
    "            \n",
    "            # Wilcoxon test for each pair of tokenizers\n",
    "            w_stat_default_vs_cased, w_p_default_vs_cased = wilcoxon(data_default_bert, data_cased_bert)\n",
    "            w_stat_default_vs_custom, w_p_default_vs_custom = wilcoxon(data_default_bert, data_custom_tokenizer)\n",
    "            w_stat_cased_vs_custom, w_p_cased_vs_custom = wilcoxon(data_cased_bert, data_custom_tokenizer)\n",
    "            \n",
    "            results.append({\n",
    "                'Dataset': dataset_name,\n",
    "                'Preprocessing': preprocessing,\n",
    "                'Hyperparameters': hyperparameters,\n",
    "                'T-test p-value (Default vs Cased)': t_p_default_vs_cased,\n",
    "                'T-test p-value (Default vs Custom)': t_p_default_vs_custom,\n",
    "                'T-test p-value (Cased vs Custom)': t_p_cased_vs_custom,\n",
    "                'Wilcoxon p-value (Default vs Cased)': w_p_default_vs_cased,\n",
    "                'Wilcoxon p-value (Default vs Custom)': w_p_default_vs_custom,\n",
    "                'Wilcoxon p-value (Cased vs Custom)': w_p_cased_vs_custom\n",
    "            })\n",
    "    return results\n",
    "\n",
    "\n",
    "# Perform the comparisons for both datasets\n",
    "bbc_preprocessing_results = compare_preprocessing(df, 'BBC')\n",
    "imdb_preprocessing_results = compare_preprocessing(df, 'IMDb')\n",
    "\n",
    "bbc_hyperparameters_results = compare_hyperparameters(df, 'BBC')\n",
    "imdb_hyperparameters_results = compare_hyperparameters(df, 'IMDb')\n",
    "\n",
    "bbc_tokenizers_results = compare_tokenizers(df, 'BBC')\n",
    "imdb_tokenizers_results = compare_tokenizers(df, 'IMDb')\n",
    "\n",
    "# Convert results to DataFrames\n",
    "bbc_preprocessing_df = pd.DataFrame(bbc_preprocessing_results)\n",
    "imdb_preprocessing_df = pd.DataFrame(imdb_preprocessing_results)\n",
    "\n",
    "bbc_hyperparameters_df = pd.DataFrame(bbc_hyperparameters_results)\n",
    "imdb_hyperparameters_df = pd.DataFrame(imdb_hyperparameters_results)\n",
    "\n",
    "bbc_tokenizers_df = pd.DataFrame(bbc_tokenizers_results)\n",
    "imdb_tokenizers_df = pd.DataFrame(imdb_tokenizers_results)\n",
    "\n",
    "\n",
    "# Display the results\n",
    "print(\"BBC Preprocessing Comparisons\")\n",
    "print(bbc_preprocessing_df)\n",
    "\n",
    "print(\"\\nIMDb Preprocessing Comparisons\")\n",
    "print(imdb_preprocessing_df)\n",
    "\n",
    "print(\"\\nBBC Hyperparameters Comparisons\")\n",
    "print(bbc_hyperparameters_df)\n",
    "\n",
    "print(\"\\nIMDb Hyperparameters Comparisons\")\n",
    "print(imdb_hyperparameters_df)\n",
    "\n",
    "print(\"\\nBBC Tokenizers Comparisons\")\n",
    "print(bbc_tokenizers_df)\n",
    "\n",
    "print(\"\\nIMDb Tokenizers Comparisons\")\n",
    "print(imdb_tokenizers_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
